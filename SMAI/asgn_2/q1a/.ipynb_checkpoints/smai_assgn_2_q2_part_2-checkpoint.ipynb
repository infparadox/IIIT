{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NlgWPAFaaVhA"
   },
   "source": [
    "\n",
    "#  Training Complex CNN architectures.\n",
    "\n",
    "We will build and train a convolutional network on CIFAR-10 dataset. We will use popular Lenet architecture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cwQN4fI9MKEi"
   },
   "source": [
    "Load all the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2854,
     "status": "ok",
     "timestamp": 1521566864845,
     "user": {
      "displayName": "Abhijeet kumar",
      "photoUrl": "//lh5.googleusercontent.com/-0NFzi6tPjlE/AAAAAAAAAAI/AAAAAAAAE8c/MmvQ4_d77cY/s50-c-k-no/photo.jpg",
      "userId": "109494166844322946121"
     },
     "user_tz": -330
    },
    "id": "vyrNRmxEL1nt",
    "outputId": "66c98076-b078-4877-8d77-d3fadf275db3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "#os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cpu,floatX=float32\"\n",
    "#import theano\n",
    "import keras\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8hD5AgqHMEKU"
   },
   "source": [
    "## Train on CIFAR-10 dataset\n",
    "\n",
    "#### Load CIFAR 10 dataset.\n",
    "\n",
    "CIFAR-10 is the widely used dataset in deep learning community to benchmark, validate and evaluate any new findings.\n",
    "CIFAR-10 dataset contains around 60k images belonging to 10 classes. It contains 50k training and 10k test images. The dataset is available at http://www.cs.toronto.edu/~kriz/cifar.html . Please visit the webpage to know more about the dataset.\n",
    "\n",
    "\n",
    "### Download the dataset from the following link and place it under the \"./data/\" folder:\n",
    "Google Drive Link:  https://drive.google.com/file/d/1MSwc0PNIUjrbwTTpc2g9_GHeUHdRyi0W/view?usp=sharing                                                                    \n",
    "Dropbox Link: https://www.dropbox.com/s/kwpojl0msyanrfl/cifar10_pretrained_model.npz?dl=0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "T0r5eAjlL4DF"
   },
   "outputs": [],
   "source": [
    "cifar10 = np.load('./data/cifar10_data.npz')\n",
    "X_train = cifar10['X_train']\n",
    "y_train = cifar10['y_train']\n",
    "X_test = cifar10['X_test']\n",
    "y_test = cifar10['y_test']\n",
    "\n",
    "print(\"Training data:\")\n",
    "print( \"Number of examples: \", X_train.shape[0])\n",
    "print( \"Number of channels:\",X_train.shape[1] )\n",
    "print( \"Image size:\", X_train.shape[2], X_train.shape[3])\n",
    "print(\"\\n\")\n",
    "print( \"Test data:\")\n",
    "print( \"Number of examples:\", X_test.shape[0])\n",
    "print( \"Number of channels:\", X_test.shape[1])\n",
    "print( \"Image size:\",X_test.shape[2], X_test.shape[3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WW1SFybpYRIA"
   },
   "source": [
    "#### Visualize some images from CIFAR-10 dataset. \n",
    "It contains 10 classes namely, airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dj5LvOPlYSK4"
   },
   "outputs": [],
   "source": [
    "plot = []\n",
    "for i in range(1,10):\n",
    "    plot_image = X_train[100*i,:,:,:].transpose(1,2,0)\n",
    "    for j in range(1,10):\n",
    "        plot_image = np.concatenate((plot_image, X_train[100*i+j,:,:,:].transpose(1,2,0)), axis=1)\n",
    "    if i==1:\n",
    "        plot = plot_image\n",
    "    else:\n",
    "        plot = np.append(plot, plot_image, axis=0)\n",
    "\n",
    "plt.imshow(plot)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0P3X8ogpYbP4"
   },
   "source": [
    "#### Normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zZ76yl0ZYd8k"
   },
   "outputs": [],
   "source": [
    "print \"mean before normalization:\", np.mean(X_train) \n",
    "print \"std before normalization:\", np.std(X_train)\n",
    "\n",
    "mean=[0,0,0]\n",
    "std=[0,0,0]\n",
    "newX_train = np.ones(X_train.shape)\n",
    "newX_test = np.ones(X_test.shape)\n",
    "for i in xrange(3):\n",
    "    mean[i] = np.mean(X_train[:,i,:,:])\n",
    "    std[i] = np.std(X_train[:,i,:,:])\n",
    "    \n",
    "for i in xrange(3):\n",
    "    newX_train[:,i,:,:] = X_train[:,i,:,:] - mean[i]\n",
    "    newX_train[:,i,:,:] = newX_train[:,i,:,:] / std[i]\n",
    "    newX_test[:,i,:,:] = X_test[:,i,:,:] - mean[i]\n",
    "    newX_test[:,i,:,:] = newX_test[:,i,:,:] / std[i]\n",
    "        \n",
    "    \n",
    "X_train = newX_train\n",
    "X_test = newX_test\n",
    "\n",
    "print \"mean after normalization:\", np.mean(X_train)\n",
    "print \"std after normalization:\", np.std(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTtzr0maYgbW"
   },
   "source": [
    "#### Specify Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0zK_8i89YjNn"
   },
   "outputs": [],
   "source": [
    "batchSize = 50                    #-- Training Batch Size\n",
    "num_classes = 10                  #-- Number of classes in CIFAR-10 dataset\n",
    "num_epochs = 10                   #-- Number of epochs for training   \n",
    "learningRate= 0.001               #-- Learning rate for the network\n",
    "lr_weight_decay = 0.95            #-- Learning weight decay. Reduce the learn rate by 0.95 after epoch\n",
    "\n",
    "\n",
    "img_rows, img_cols = 32, 32       #-- input image dimensions\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKvIvhkVYk89"
   },
   "source": [
    "#### Lets build a CNN network (LeNet) in Theano Keras and train on CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "V844FNHAYnSW"
   },
   "outputs": [],
   "source": [
    "model = Sequential()                                                #-- Sequential container.\n",
    "\n",
    "model.add(Convolution2D(6, 5, 5,                                    #-- 6 outputs (6 filters), 5x5 convolution kernel\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(3, img_rows, img_cols)))       #-- 3 input depth (RGB)\n",
    "model.add(Activation('relu'))                                       #-- ReLU non-linearity \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))                           #-- A max-pooling on 2x2 windows\n",
    "model.add(Convolution2D(16, 5, 5))                                  #-- 16 outputs (16 filters), 5x5 convolution kernel\n",
    "model.add(Activation('relu'))                                       #-- ReLU non-linearity\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))                           #-- A max-pooling on 2x2 windows\n",
    "\n",
    "model.add(Flatten())                                                #-- eshapes a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "model.add(Dense(120))                                               #-- 120 outputs fully connected layer\n",
    "model.add(Activation('relu'))                                       #-- ReLU non-linearity \n",
    "model.add(Dense(84))                                                #-- 84 outputs fully connected layer\n",
    "model.add(Activation('relu'))                                       #-- ReLU non-linearity \n",
    "model.add(Dense(num_classes))                                       #-- 10 outputs fully connected layer (one for each class)\n",
    "model.add(Activation('softmax'))                                    #-- converts the output to a log-probability. Useful for classification problems\n",
    "\n",
    "print model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NjxIFfzNYpbO"
   },
   "source": [
    "#### Compile and then train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "96ukQ_wJYtTU"
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=learningRate, decay = lr_weight_decay)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#-- switch verbose=0 if you get error \"I/O operation from closed file\"\n",
    "history = model.fit(X_train, Y_train, batch_size=batchSize, nb_epoch=num_epochs,\n",
    "          verbose=1, shuffle=True, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-r21LOfyYvOu"
   },
   "source": [
    "#### Print the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "natTe_gdYxRV"
   },
   "outputs": [],
   "source": [
    "#-- summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#-- summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2O59SdYdY1tb"
   },
   "outputs": [],
   "source": [
    "#-- test the network\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print 'Test score:', score[0] \n",
    "print 'Test accuracy:', score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JOl807xzY3ox"
   },
   "source": [
    "#### save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PfXbKz9lY57Q"
   },
   "outputs": [],
   "source": [
    "#cifar10_weights = model.get_weights()\n",
    "#np.savez(\"cifar10_weights_new\", cifar10_weights = cifar10_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00Dsq2YxY743"
   },
   "source": [
    "\n",
    "** Q1: [0.5 point] **\n",
    "\n",
    "What are the number of parameters in convolution layers with K filters each of size 3*w*h.\n",
    "\n",
    "** Q2: [0.5 points] ** \n",
    "\n",
    "What are the number of parameters in a max pooling operation? \n",
    "\n",
    "**Q3: [0.5 point]**\n",
    "\n",
    "Which of the operations contain most number of parameters?\n",
    "      (a) conv (b) pool (c) Fully connected layer (FC) (d) Relu \n",
    "\n",
    "**Q4: [0.5 point]**\n",
    "\n",
    "Which operation consume most amount of memory?\n",
    "     (a) initial convolution layers (b) fully connected layers at the end\n",
    "\n",
    "** Q5: [2 points] **\n",
    "\n",
    "Experiment with **learning rate** (learningRate) and notice the behaviour of the learning process. Plot your observations in a graph with brief explanation.\n",
    "Take the values on a log scale. Vary only one parameter at a time.\n",
    "\n",
    "\n",
    "** Q6: [2 points] **\n",
    "\n",
    "Currently, the **batch-size** is 50. Notice the training loss curve if batch size is changed to 1. Is it smooth or fluctating? Show the effect of batch-size on the learning curves in a plot.\n",
    "Take the values on a log scale. Vary only one parameter at a time.\n",
    "\n",
    "** Q7: [2 points] **\n",
    "\n",
    "Increase the **number of convolution filters** and experiment. Present your observations using plots and brief explanations.\n",
    "Take the values on a log scale. Vary only one parameter at a time.\n",
    "\n",
    "** Q8: [2 points] **\n",
    "\n",
    "What do you observe if you increase the **number of layers** (depth of the network) ? Present your observations using plots and brief explanations. \n",
    "\n",
    "** Q9: [2 points] **\n",
    "\n",
    "What do you observe if you increase the **activation functions** (tanh, relu, sigmoid) ? Present your observations using plots and brief explanations. \n",
    "\n",
    "** Q10: [1 points] **\n",
    "\n",
    "CNN training requires lot of training data. In the absence of large training data, a common practice is to use synthetic data using operations such as flipping, scaling, etc. Can you think of any other two operations techniques that can help to increase the training set? Demonstrate these effects with sufficient explanation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzsoSw9uani8"
   },
   "source": [
    "\n",
    "```\n",
    "This code is a modified version of the code from Deep-Learning School which took place at IIIT-Hyd in Summers 2017 and Summers 2016\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "smai_assgn_2_q2_part_2.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
